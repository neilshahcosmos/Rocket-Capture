{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import integrate, interpolate\n",
    "import scipy.fft as fft\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Rocket Parameters\n",
    "xi = 50\n",
    "Gmu = 1e-12\n",
    "GammaFrac = 0.1\n",
    "vf = 0.3\n",
    "nRockets = 1000\n",
    "\n",
    "# Global Simulation Parameters\n",
    "tmax = 100\n",
    "L = 1\n",
    "binS = 100\n",
    "zi = 127\n",
    "dx = L / binS\n",
    "h = 0.7\n",
    "rhoScale = 4.78e-20 # Mpc / Msun\n",
    "\n",
    "# Global Physical Parameters\n",
    "t0 = 4213 / h # Mpc / h\n",
    "H0 = 0.0003333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster dirs\n",
    "homeDir = \"/cluster/tufts/hertzberglab/nshah14/\"\n",
    "sharedDir = \"/cluster/tufts/hertzberglab/shared/Rockets/\"\n",
    "simName = \"Sim_100v\"\n",
    "simDir = sharedDir + simName + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHubbleEvol():\n",
    "    OMatter = 0.25\n",
    "    OLambda = 0.75\n",
    "\n",
    "    da_dt = lambda a, t: a * H0 * np.sqrt(OMatter / a**3 + OLambda)\n",
    "\n",
    "    a0 = 1 / (1 + zi)\n",
    "    tInt = np.linspace(0, 1.1 / H0, 1000)\n",
    "    af = interpolate.InterpolatedUnivariateSpline(tInt, integrate.odeint(da_dt, y0=a0, t=tInt)[:, 0])\n",
    "    aDotf = af.derivative(n=1)\n",
    "    tEnd = sp.optimize.fsolve(lambda t: af(t) - 1.0, x0=(1.0 / H0))[0]\n",
    "\n",
    "    tArr = np.asarray([(tEnd + t)**(t / tmax) - 1 for t in range(tmax)])\n",
    "    aArr = np.asarray([af(t) for t in tArr])\n",
    "    HArr = np.asarray([aDotf(t) / af(t) for t in tArr])\n",
    "\n",
    "    return tArr, aArr, HArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFg(t, pos, rhokL):\n",
    "    x, y, z = list(map(int, np.floor(pos)))\n",
    "    if x <= 0 or y <= 0 or z <= 0 or x >= binS-1 or y >= binS-1 or z >= binS-1:\n",
    "        return np.zeros(3) \n",
    "    else:\n",
    "        kArr = getkArr()\n",
    "        phix = fft.fftn(rhokL).real\n",
    "\n",
    "        try:\n",
    "            Fg = (4*np.pi / (2*dx)) * np.asarray([phix[x + 1, y, z] - phix[x - 1, y, z], phix[x, y + 1, z] - phix[x, y - 1, z], phix[x, y, z + 1] - phix[x, y, z - 1]])\n",
    "        except IndexError:\n",
    "            Fg = np.zeros(3)\n",
    "        return(Fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getkArr(override=False):\n",
    "    kArrPath = simDir + \"kArr__L_{:03d}__bins_{:03d}.npy\".format(L, binS)\n",
    "    if os.path.exists(kArrPath) and not override:\n",
    "        kArr = np.load(kArrPath)\n",
    "        return(kArr)\n",
    "\n",
    "    kArr = np.zeros((binS, binS, binS), dtype=float)\n",
    "    halfBins = int(binS / 2)\n",
    "    for i in range(binS):\n",
    "        for j in range(binS):\n",
    "            for k in range(binS):\n",
    "                lx = - (4 * binS**2 / L**2) * np.sin((np.pi / binS) * (i - halfBins))**2\n",
    "                ly = - (4 * binS**2 / L**2) * np.sin((np.pi / binS) * (j - halfBins))**2\n",
    "                lz = - (4 * binS**2 / L**2) * np.sin((np.pi / binS) * (k - halfBins))**2\n",
    "                if i == halfBins and j == halfBins and k == halfBins:\n",
    "                    kArr[i, j, k] = 1\n",
    "                else:\n",
    "                    kArr[i, j, k] = lx + ly + lz\n",
    "    \n",
    "    np.save(kArrPath, kArr)\n",
    "    return kArr\n",
    "\n",
    "def getRhokLambda(t, kArr):\n",
    "    rhox = getRhoxZoom(t)\n",
    "    rhok = fft.ifftn(rhox)\n",
    "\n",
    "    halfBins = int(binS / 2)\n",
    "    rhokL = np.divide(rhok, kArr)\n",
    "    rhokL[halfBins, halfBins, halfBins] = 0\n",
    "    \n",
    "    return(rhokL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRhoxZoom(t, L=L, dx=dx, override=False):\n",
    "    snapDir = simDir + \"snapdir_{:03d}/\".format(t)\n",
    "    pathArr = np.asarray(os.listdir(snapDir))\n",
    "    \n",
    "    saveDir = simDir + simName + \"_rhoXZoom__L_{:03d}Mpc__dx_{:03d}kPc/\".format(L, int(1000 * dx))\n",
    "    if not os.path.exists(saveDir):\n",
    "        os.makedirs(saveDir)\n",
    "    savePath = saveDir + \"rhoXZoom__L_{:03d}Mpc__dx_{:03d}kPc__t_{:03d}.npy\".format(L, int(1000 * dx), t)\n",
    "\n",
    "    if os.path.exists(savePath) and not override:\n",
    "        rhoxZoom = np.load(savePath)\n",
    "        return(rhoxZoom)\n",
    "    else:\n",
    "        ptypeN = 3\n",
    "        massArr = getMass()\n",
    "        haloC = getHaloC(tmax)\n",
    "        binS = int(L / dx)\n",
    "        rhoxZoom = np.zeros((binS, binS, binS))\n",
    "        for pi in np.arange(0, ptypeN):\n",
    "            ptype = pi + 1\n",
    "            mi = massArr[pi]\n",
    "            \n",
    "            for pathi in np.arange(0, pathArr.size):\n",
    "                datGet = \"/PartType{:d}/Coordinates\".format(ptype)\n",
    "                try:\n",
    "                    coords = np.asarray(h5py.File(snapDir + pathArr[pathi], 'r')[datGet])\n",
    "                except KeyError:\n",
    "                    # print(\"   (Warning! Could not find ptype {:d} for snapshot t = {:d})\".format(ptype, t))\n",
    "                    pass\n",
    "\n",
    "                for ci, coord in enumerate(coords):\n",
    "                    i, j, k = list(map(int, np.floor((coord - haloC + L/2) / dx)))\n",
    "                    if i < 0 or i > binS - 1 or j < 0 or j > binS - 1 or k < 0 or k > binS - 1:\n",
    "                        continue\n",
    "                    try:\n",
    "                        rhoxZoom[i, j, k] += mi\n",
    "                    except IndexError:\n",
    "                        print(\"Indexing Error! i, j, k = {}\".format([i, j, k]))\n",
    "                        return -1\n",
    "        rhoxZoom *= rhoScale * 1e10\n",
    "        np.save(savePath, rhoxZoom)\n",
    "        return(rhoxZoom)\n",
    "\n",
    "def rhoInstantiate(redo=[]):\n",
    "    t0 = time.time()\n",
    "    override = False\n",
    "    for t in range(0, tmax):\n",
    "        catch = getRhoxZoom(t, L=L, dx=dx, override=False)\n",
    "        if np.mod(t, 10) == 0:\n",
    "            print(\"   Processing t = {}/{} (Time Elapsed: {}, Estimated Time Remaining: {})\".format(t + 1, tmax, toMS(time.time() - t0), toMS((tmax / (t + 1) - 1) * (time.time() - t0))))\n",
    "    \n",
    "    print(\"Finished Instantiating Density Matrices! Took: {}\\n\".format(toMS(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMass():\n",
    "    tFix = 50\n",
    "    massTab = np.zeros(3)\n",
    "\n",
    "    snapDir = simDir + \"snapdir_{:03d}/\".format(tFix)\n",
    "    path1 = snapDir + \"snapshot_{:03d}.0.hdf5\".format(tFix)\n",
    "    fil = h5py.File(path1, 'r')\n",
    "\n",
    "    ptypeN = 3\n",
    "    for pi in np.arange(0, ptypeN):\n",
    "        ptype = pi + 1\n",
    "        datGet = \"/PartType{:d}/Masses\".format(ptype)\n",
    "        massTab[pi] = np.asarray(fil[datGet])[0]\n",
    "\n",
    "    return massTab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toMS(t):\n",
    "    s = np.floor(np.mod(t, 60))\n",
    "    m = np.floor(np.mod(t, 3600) / 60)\n",
    "    h = np.floor(t / 3600)\n",
    "\n",
    "    if t < 1:\n",
    "        tstr = \"{:f} s\".format(t)\n",
    "    elif t < 3600:\n",
    "        tstr = \"{:02d}m {:02d}s\".format(int(m), int(s))\n",
    "    else:\n",
    "        tstr = \"{}h {:02d}m {:02d}s\".format(int(h), int(m), int(s))\n",
    "    return tstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHaloC(t):\n",
    "    haloFinalDir = simDir + \"snapdir_{:03d}/\".format(t)\n",
    "    pathArr = np.asarray(os.listdir(haloFinalDir))\n",
    "    haloFinalCoords = np.empty((0, 3))\n",
    "\n",
    "    for pathi in np.arange(0, pathArr.size):\n",
    "        datGet = \"/PartType1/Coordinates\"\n",
    "        try:\n",
    "            coords = np.asarray(h5py.File(haloFinalDir + pathArr[pathi], 'r')[datGet])\n",
    "        except KeyError:\n",
    "            continue\n",
    "        haloFinalCoords = np.concatenate([haloFinalCoords, coords], axis=0)\n",
    "\n",
    "    haloC = np.asarray([np.mean(haloFinalCoords[:, i]) for i in range(3)])\n",
    "    return(haloC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoords(t):\n",
    "    snapDir = simDir + \"snapdir_{:03d}/\".format(t)\n",
    "    pathArr = np.asarray(os.listdir(snapDir))\n",
    "    \n",
    "    ptypeN = 3\n",
    "    coordsArr = [np.empty((0, 3)) for i in range(ptypeN)]\n",
    "    for pi in np.arange(0, ptypeN):\n",
    "        ptype = pi + 1\n",
    "        \n",
    "        for pathi in np.arange(0, pathArr.size):\n",
    "            datGet = \"/PartType{:d}/Coordinates\".format(ptype)\n",
    "            try:\n",
    "                coords = np.asarray(h5py.File(snapDir + pathArr[pathi], 'r')[datGet])\n",
    "            except KeyError:\n",
    "                # print(\"   (Warning! Could not find ptype {:d} for snapshot t = {:d})\".format(ptype, t))\n",
    "                continue\n",
    "\n",
    "            coordsArr[pi] = np.concatenate([coordsArr[pi], coords], axis=0)\n",
    "    \n",
    "    return(coordsArr)\n",
    "\n",
    "def getHaloCoords(t):\n",
    "    groupDir = simDir + \"groups_{:03d}/\".format(t)\n",
    "    snapDir = simDir + \"snapdir_{:03d}/\".format(t)\n",
    "    groupPaths = np.asarray(os.listdir(groupDir))\n",
    "    snapPaths = np.asarray(os.listdir(snapDir))\n",
    "\n",
    "    ptype = 1\n",
    "    coordsArr = np.empty((0, 3), dtype=float)\n",
    "\n",
    "    for i, pathi in enumerate(snapPaths):\n",
    "        datGet = \"/PartType{:d}/Coordinates\".format(ptype)\n",
    "        try:\n",
    "            coords = np.asarray(h5py.File(snapDir + pathi, 'r')[datGet])\n",
    "            coordsArr = np.concatenate([coordsArr, coords], axis=0)\n",
    "        except KeyError:\n",
    "            # print(\"   (Warning! Could not find ptype {:d} for snapshot t = {:d})\".format(ptype, t))\n",
    "            pass\n",
    "    \n",
    "    haloCoords = np.empty((1, 3))\n",
    "    for i, pathi in enumerate(groupPaths):\n",
    "        gfile = h5py.File(groupDir + pathi, 'r')\n",
    "        try:\n",
    "            haloInit = int(np.asarray(gfile[\"/Group/GroupOffsetType/\"])[0, 0])\n",
    "            haloN = int(np.asarray(gfile[\"/Group/GroupLen/\"])[0])\n",
    "            haloCoords = coordsArr[haloInit:(haloInit + haloN + 1), :]\n",
    "            break\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    return(haloCoords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PType Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptypeN = 3\n",
    "colorArr = np.asarray([\"k\", \"g\", \"r\"])\n",
    "\n",
    "saveDir = simDir + \"AllPtypesPlts/\"\n",
    "if not os.path.exists(saveDir):\n",
    "    os.makedirs(saveDir)\n",
    "\n",
    "coords0 = getCoords(0)\n",
    "xmin, xmax, ymin, ymax = np.asarray([[np.min(coords0[i][:, 0]), np.max(coords0[i][:, 0]), np.min(coords0[i][:, 1]), np.max(coords0[i][:, 1])] for i in range(3)]).T\n",
    "limRatio = np.asarray([1.5, 1.5, 1.2])\n",
    "pltLims = np.asarray([limRatio[i] * np.asarray([\n",
    "xmin[i] - 0.5 * (xmax[i] + xmin[i]), \n",
    "xmax[i] - 0.5 * (xmax[i] + xmin[i]),\n",
    "ymin[i] - 0.5 * (ymax[i] + ymin[i]),\n",
    "ymax[i] - 0.5 * (ymax[i] + ymin[i])]) for i in range(3)])\n",
    "\n",
    "T0 = time.time()\n",
    "for t in range(tmax):\n",
    "    print(\"Processing: {:03d}/{:03d} (Time Elapsed: {}, Estimated Time Remaining: {})\".format(t, tmax, toMS(time.time() - T0), toMS((tmax / (t + 1) - 1) * (time.time() - T0))))\n",
    "    coordsArr = getCoords(t)\n",
    "\n",
    "    fig1, axs1 = plt.subplots(1, 3, figsize=(26, 8), dpi=100)\n",
    "    for pi in range(ptypeN):\n",
    "        xc = np.mean(coordsArr[pi][:, 0])\n",
    "        yc = np.mean(coordsArr[pi][:, 1])\n",
    "\n",
    "        axi = axs1[pi]\n",
    "        axi.scatter(coordsArr[pi][:, 0] - xc, coordsArr[pi][:, 1] - yc, c=colorArr[pi], s=0.1)\n",
    "        axi.title.set_text(\"ptype = {:d}, t = {:03d}\".format(pi + 1, t))\n",
    "        axi.set_xlim([pltLims[pi, 0], pltLims[pi, 1]])\n",
    "        axi.set_ylim([pltLims[pi, 2], pltLims[pi, 3]])\n",
    "    plt.savefig(saveDir + \"AllPtypesPlts_Separated__t_{:03d}\".format(t))\n",
    "    plt.close()\n",
    "\n",
    "    fig2, axs2 = plt.subplots(figsize=(8, 8), dpi=100)\n",
    "    for pi in range(ptypeN):\n",
    "        plt.scatter(coordsArr[pi][:, 0], coordsArr[pi][:, 1], c=colorArr[pi], s=0.1, zorder=(3 - pi), label=\"ptype = {}\".format(pi + 1))\n",
    "    plt.title(\"t = {:03d}\".format(t))\n",
    "    plt.savefig(saveDir + \"AllPtypesPlts_Overlayed__t_{:03d}\".format(t))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group ID Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haloCArr = np.zeros((tmax, 3))\n",
    "# for t in range(tmax):\n",
    "#     haloCoords = getHaloCoords(t)\n",
    "#     if haloCoords.shape[0] > 1:\n",
    "#         haloCArr[t, :] = np.asarray([np.mean(haloCoords[:, j]) for j in range(3)])\n",
    "#     else:\n",
    "#         haloCArr[t, :] = np.asarray([-1, -1, -1])\n",
    "    \n",
    "#     if (np.mod(t, 10) == 0):\n",
    "#         print(\"Processing: {}/{}\".format(t, tmax))\n",
    "\n",
    "# np.save(simDir + \"haloCenters.npy\", haloCArr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bf40accb7e9f78ce3ef5eb39a536e85ee79f4dae9e32f4b9fcd93ba1ec84f31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
